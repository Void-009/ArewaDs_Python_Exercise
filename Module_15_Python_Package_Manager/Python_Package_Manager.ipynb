{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Package Manager Exercises:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "Read this url and find the 10 most frequent words. romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('lia', 23), ('a', 17), ('li', 14), ('meta', 13), ('div', 13), ('ul', 10), ('input', 9), ('link', 7), ('gutenberg', 5), ('of', 5)]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Function to clean the text\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation using regular expression\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Function to find the most common words in the text\n",
    "def find_most_common_words_from_url(url, n):\n",
    "    # Download the content from the URL\n",
    "    response = requests.get(url)\n",
    "    text = response.text\n",
    "\n",
    "    # Clean the text\n",
    "    cleaned_text = clean_text(text)\n",
    "\n",
    "    # Split the text into words\n",
    "    words = cleaned_text.split()\n",
    "\n",
    "    # Count word frequencies\n",
    "    word_counts = Counter(words)\n",
    "\n",
    "    # Get the n most common words as a list of tuples\n",
    "    most_common = word_counts.most_common(n)\n",
    "\n",
    "    return most_common\n",
    "\n",
    "\n",
    "romeo_and_juliet_url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "\n",
    "most_common_words = find_most_common_words_from_url(romeo_and_juliet_url, 10)\n",
    "\n",
    "print(most_common_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "Read the cats API and cats_api = 'https://api.thecatapi.com/v1/breeds' and find :\n",
    " * the min, max, mean, median, standard deviation of cats' weight in metric units.\n",
    "* the min, max, mean, median, standard deviation of cats' lifespan in years.\n",
    "* Create a frequency table of country and breed of cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight statistics (in kg):\n",
      "Min: 3.00, Max: 7.50, Mean: 4.71, Median: 4.50, Standard Deviation: 1.06\n",
      "\n",
      "Lifespan statistics (in years):\n",
      "Min: 8, Max: 18, Mean: 12.07, Median: 12.0, Standard Deviation: 1.81\n",
      "\n",
      "Frequency table of country and breed:\n",
      "     Country             Breed  Count\n",
      "0  Australia   Australian Mist      1\n",
      "1      Burma           Burmese      1\n",
      "2      Burma  European Burmese      1\n",
      "3     Canada            Cymric      1\n",
      "4     Canada            Sphynx      1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch data from the API\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "response = requests.get(cats_api)\n",
    "cats_data = response.json()\n",
    "\n",
    "# Extract weights and lifespans\n",
    "weights = []\n",
    "lifespan = []\n",
    "countries = []\n",
    "breeds = []\n",
    "\n",
    "for cat in cats_data:\n",
    "    # Extract weight in metric units (kg)\n",
    "    if cat['weight']['metric']:\n",
    "        weight = cat['weight']['metric'].split(\" - \")\n",
    "        weight_min = float(weight[0]) if weight[0] != \"null\" else None\n",
    "        weight_max = float(weight[1]) if weight[1] != \"null\" else None\n",
    "        if weight_min and weight_max:\n",
    "            weights.append((weight_min + weight_max) / 2)  # Use the average weight if both min/max are available\n",
    "\n",
    "    # Extract lifespan in years\n",
    "    if cat['life_span']:\n",
    "        lifespan.append(int(cat['life_span'].split(\" \")[0]))  # Extract the first number (age in years)\n",
    "\n",
    "    # Extract country of origin and breed name\n",
    "    countries.append(cat['origin'])\n",
    "    breeds.append(cat['name'])\n",
    "\n",
    "# Calculate statistics for weight (in kg) and lifespan (in years)\n",
    "weights = [w for w in weights if w is not None]  # Remove None values from weights\n",
    "\n",
    "# Weight statistics\n",
    "weight_min = np.min(weights)\n",
    "weight_max = np.max(weights)\n",
    "weight_mean = np.mean(weights)\n",
    "weight_median = np.median(weights)\n",
    "weight_std = np.std(weights)\n",
    "\n",
    "# Lifespan statistics\n",
    "lifespan_mean = np.mean(lifespan)\n",
    "lifespan_median = np.median(lifespan)\n",
    "lifespan_min = np.min(lifespan)\n",
    "lifespan_max = np.max(lifespan)\n",
    "lifespan_std = np.std(lifespan)\n",
    "\n",
    "# Frequency table for country and breed\n",
    "df = pd.DataFrame({\n",
    "    'Country': countries,\n",
    "    'Breed': breeds\n",
    "})\n",
    "\n",
    "# Create frequency table\n",
    "country_breed_frequency = df.groupby(['Country', 'Breed']).size().reset_index(name='Count')\n",
    "\n",
    "# Output the results\n",
    "print(f\"Weight statistics (in kg):\")\n",
    "print(f\"Min: {weight_min:.2f}, Max: {weight_max:.2f}, Mean: {weight_mean:.2f}, Median: {weight_median:.2f}, Standard Deviation: {weight_std:.2f}\")\n",
    "print(f\"\\nLifespan statistics (in years):\")\n",
    "print(f\"Min: {lifespan_min}, Max: {lifespan_max}, Mean: {lifespan_mean:.2f}, Median: {lifespan_median}, Standard Deviation: {lifespan_std:.2f}\")\n",
    "print(\"\\nFrequency table of country and breed:\")\n",
    "print(country_breed_frequency.head())  # Show only the first few rows for brevity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "Read the countries API and find\n",
    "* the 10 largest countries\n",
    "* the 10 most spoken languages\n",
    "* the total number of languages in the countries API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Largest Countries by Population:\n",
      "China: 1402112000\n",
      "India: 1380004385\n",
      "United States: 329484123\n",
      "Indonesia: 273523621\n",
      "Pakistan: 220892331\n",
      "Brazil: 212559409\n",
      "Nigeria: 206139587\n",
      "Bangladesh: 164689383\n",
      "Russia: 144104080\n",
      "Mexico: 128932753\n",
      "\n",
      "Top 10 Most Spoken Languages:\n",
      "English: 91\n",
      "French: 46\n",
      "Arabic: 25\n",
      "Spanish: 24\n",
      "Portuguese: 10\n",
      "Dutch: 7\n",
      "Russian: 7\n",
      "German: 6\n",
      "Chinese: 5\n",
      "Italian: 4\n",
      "\n",
      "Total number of unique languages: 155\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "# Fetch countries data from the API\n",
    "url = \"https://restcountries.com/v3.1/all\"  # API endpoint that provides data for all countries\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the response is successful\n",
    "if response.status_code != 200:\n",
    "    print(\"Error fetching data from the API.\")\n",
    "else:\n",
    "    countries_data = response.json()\n",
    "\n",
    "    # --- 1. Find the 10 largest countries by population ---\n",
    "    countries_population = [(country['name']['common'], country['population']) for country in countries_data]\n",
    "    countries_population.sort(key=lambda x: x[1], reverse=True)  # Sort by population in descending order\n",
    "    largest_countries = countries_population[:10]\n",
    "\n",
    "    print(\"Top 10 Largest Countries by Population:\")\n",
    "    for country, population in largest_countries:\n",
    "        print(f\"{country}: {population}\")\n",
    "\n",
    "    # --- 2. Find the 10 most spoken languages ---\n",
    "    language_count = Counter()\n",
    "\n",
    "    # Loop through each country and count the languages spoken\n",
    "    for country in countries_data:\n",
    "        if 'languages' in country:\n",
    "            for language in country['languages'].values():\n",
    "                language_count[language] += 1\n",
    "\n",
    "    # Get the 10 most common languages\n",
    "    most_spoken_languages = language_count.most_common(10)\n",
    "\n",
    "    print(\"\\nTop 10 Most Spoken Languages:\")\n",
    "    for language, count in most_spoken_languages:\n",
    "        print(f\"{language}: {count}\")\n",
    "\n",
    "    # --- 3. Count the total number of languages across all countries ---\n",
    "    total_languages = len(language_count)\n",
    "    print(f\"\\nTotal number of unique languages: {total_languages}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "UCI is one of the most common places to get data sets for data science and machine learning. Read the content of UCL (https://archive.ics.uci.edu/ml/datasets.php). Without additional libraries it will be difficult, so you may try it with BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to retrieve data from https://archive.ics.uci.edu/ml/datasets.php. Status code: 404\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# The URL for UCI Machine Learning Datasets page\n",
    "url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "\n",
    "# Send a GET request to fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code != 200:\n",
    "    print(f\"Failed to retrieve data from {url}. Status code: {response.status_code}\")\n",
    "else:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the main section where datasets are listed\n",
    "    datasets_section = soup.find_all('tr')  # We can use all 'tr' tags to check the tables\n",
    "    \n",
    "    # Initialize a list to store dataset names and links\n",
    "    datasets = []\n",
    "\n",
    "    # Loop through all rows in the table (skip headers and other unnecessary rows)\n",
    "    for row in datasets_section:\n",
    "        # Find all columns within each row (this corresponds to dataset names and links)\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) > 1:  # This will ensure that we only work with rows that have data\n",
    "            dataset_name = cols[0].get_text(strip=True)\n",
    "            # The link to the dataset is within the first column and is wrapped inside an <a> tag\n",
    "            link = cols[0].find('a')\n",
    "            if link:\n",
    "                dataset_link = 'https://archive.ics.uci.edu' + link.get('href')\n",
    "                datasets.append((dataset_name, dataset_link))\n",
    "\n",
    "    # Print the first 10 datasets (name and link)\n",
    "    print(\"First 10 Datasets from the UCI Repository:\")\n",
    "    for i, dataset in enumerate(datasets[:10]):\n",
    "        print(f\"{i+1}. {dataset[0]} - {dataset[1]}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
